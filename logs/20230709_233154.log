2023-07-09 23:31:54,400 - INFO - Ingesting data with config DataIngestionConfig(train_data_path=data\train, test_data_path=data\validation, load_images=<function load_image at 0x000001EDB75755E0>)
2023-07-09 23:31:59,225 - INFO - Transforming data with DataTransformationConfig(channel_features=['mean', 'std', 'median', 'mode', 'min', 'max', 'range', 'skewness', 'kurtosis', 'entropy', 'quantile_0.25', 'quantile_0.75', 'iqr'], histogram_features=['mean', 'std', 'median', 'mode', 'min', 'max', 'range', 'skewness', 'kurtosis', 'entropy', 'R'], coocurrence_matrix_features=['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation'], to_grayscale=<function to_grayscale at 0x000001EDB7575700>, to_histogram=<function to_histogram at 0x000001EDB7674940>)
2023-07-09 23:32:52,260 - INFO - Saving features in data\train_features.csv and data\test_features.csv
2023-07-09 23:32:52,563 - INFO - Training models with features with config ModelTrainerConfig(k_features_grid=[10, 20, 40, 'all'], feature_selection_score_function=<function mutual_info_classif at 0x000001EDB75751F0>, models=[Model(model_name=Logistic Regression, model_parameter_grid={'C': [0.1, 0.5, 1.0, 2.0, 5.0], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'max_iter': [200, 500, 1000], 'n_jobs': [-1], 'random_state': [42]}, model=LogisticRegression()), Model(model_name=Random Forest, model_parameter_grid={'n_estimators': [100, 200, 500, 1000], 'criterion': ['gini', 'entropy', 'log_loss'], 'max_depth': [None, 10, 20, 50, 100]}, model=RandomForestClassifier()), Model(model_name=KNN, model_parameter_grid={'n_neighbors': [3, 5, 7, 9, 11, 13, 15], 'weights': ['distance'], 'p': [1, 2], 'n_jobs': [-1]}, model=KNeighborsClassifier()), Model(model_name=SVM, model_parameter_grid={'C': [0.1, 0.5, 1.0, 2.0, 5.0], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'degree': [1, 2, 3, 4, 5], 'gamma': ['scale', 'auto'], 'max_iter': [200, 500, 1000], 'random_state': [42]}, model=SVC()), Model(model_name=Decision Tree, model_parameter_grid={'criterion': ['gini', 'entropy'], 'splitter': ['best'], 'max_depth': [None, 5, 10, 50, 100], 'random_state': [42]}, model=DecisionTreeClassifier())], target_column=label, score_criteria=f1_micro, cv=5)
2023-07-10 00:42:49,516 - INFO - Saving results in results\results.csv
2023-07-10 00:42:49,518 - INFO - Saving best model in models\best_model.pkl
